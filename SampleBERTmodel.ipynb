{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import pipeline\n","\n","# Load pre-trained model for question answering\n","qa_pipeline = pipeline(\"question-answering\", model=\"/opt/bert-base-cased\", tokenizer=\"/opt/bert-base-cased\")\n","\n","# Example context and question\n","context = \"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained model for natural language processing tasks.\"\n","question = \"What is BERT?\"\n","\n","# Set max_length parameter to a larger value\n","max_length = 512  # You can adjust this value based on your needs\n","\n","# Perform question answering with max_length\n","answer = qa_pipeline(question=question, context=context, max_length=max_length)\n","\n","# Print the full answer\n","print(\"Answer:\", answer['answer'])"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
